# See http://www.robotstxt.org/wc/norobots.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
# User-Agent: *
# Disallow: /

User-agent: Yandex 
Crawl-delay: 2
Disallow: /*/login/
Disallow: /*/register/
Sitemap: http://job4fun.ru/sitemap1.xml.gz
Host: job4fun.ru

User-agent: Google
Crawl-delay: 2
Disallow: /*/login/
Disallow: /*/register/
Sitemap: http://job4fun.ru/sitemap1.xml.gz
Host: job4fun.ru

User-agent: Slurp
Crawl-delay: 8
Disallow: /*/login/
Disallow: /*/register/
Sitemap: http://job4fun.ru/sitemap1.xml.gz
Host: job4fun.ru

User-agent: *
Crawl-delay: 10
Disallow: /*/login/
Disallow: /*/register/
Sitemap: http://job4fun.ru/sitemap1.xml.gz
Host: job4fun.ru
